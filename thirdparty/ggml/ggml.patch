diff --git a/examples/llava/clip.cpp b/examples/llava/clip.cpp
index ef9e4ba7..a1b49793 100644
--- a/examples/llava/clip.cpp
+++ b/examples/llava/clip.cpp
@@ -859,6 +859,7 @@ struct clip_ctx * clip_model_load(const char * fname, const int verbosity = 1) {
 
     // kv
     const int n_kv = gguf_get_n_kv(ctx);
+    if (verbosity >= 1) {
     printf("%s: loaded meta data with %d key-value pairs and %d tensors from %s\n",
         __func__, n_kv, n_tensors, fname);
     {
@@ -898,6 +899,7 @@ struct clip_ctx * clip_model_load(const char * fname, const int verbosity = 1) {
             printf("%s: - type %4s: %4d tensors\n", __func__, ggml_type_name(kv.first), kv.second);
         }
     }
+    }
 
     // data
     size_t model_size = 0;
@@ -937,18 +939,18 @@ struct clip_ctx * clip_model_load(const char * fname, const int verbosity = 1) {
 
 #ifdef GGML_USE_CUDA
     new_clip->backend = ggml_backend_cuda_init(0);
-    printf("%s: CLIP using CUDA backend\n", __func__);
+    if (verbosity >= 1) printf("%s: CLIP using CUDA backend\n", __func__);
 #endif
 
 #ifdef GGML_USE_METAL
     new_clip->backend = ggml_backend_metal_init();
-    printf("%s: CLIP using Metal backend\n", __func__);
+    if (verbosity >= 1) printf("%s: CLIP using Metal backend\n", __func__);
 #endif
 
 
     if (!new_clip->backend) {
         new_clip->backend = ggml_backend_cpu_init();
-        printf("%s: CLIP using CPU backend\n", __func__);
+        if (verbosity >= 1) printf("%s: CLIP using CPU backend\n", __func__);
     }
 
     // model size and capabilities
@@ -980,7 +982,7 @@ struct clip_ctx * clip_model_load(const char * fname, const int verbosity = 1) {
         }
     }
 
-    printf("%s: params backend buffer size = % 6.2f MB (%i tensors)\n", __func__, model_size / (1024.0 * 1024.0), n_tensors);
+    if (verbosity >= 1) printf("%s: params backend buffer size = % 6.2f MB (%i tensors)\n", __func__, model_size / (1024.0 * 1024.0), n_tensors);
 
     // load tensors
     {
@@ -1216,7 +1218,7 @@ struct clip_ctx * clip_model_load(const char * fname, const int verbosity = 1) {
         ggml_cgraph * gf = clip_image_build_graph(new_clip, &batch);
         ggml_gallocr_reserve(new_clip->compute_alloc, gf);
         size_t compute_memory_buffer_size = ggml_gallocr_get_buffer_size(new_clip->compute_alloc, 0);
-        printf("%s: compute allocated memory: %.2f MB\n", __func__, compute_memory_buffer_size /1024.0/1024.0);
+        if (verbosity >= 1) printf("%s: compute allocated memory: %.2f MB\n", __func__, compute_memory_buffer_size /1024.0/1024.0);
     }
 
     return new_clip;
diff --git a/examples/llava/llava.cpp b/examples/llava/llava.cpp
index 98012816..e8567d8f 100644
--- a/examples/llava/llava.cpp
+++ b/examples/llava/llava.cpp
@@ -257,7 +257,7 @@ static bool encode_image_with_clip(clip_ctx * ctx_clip, int n_threads, const cli
             }
         }
         const int64_t t_img_enc_batch_us = ggml_time_us();
-        printf("%s: %d segments encoded in %8.2f ms\n", __func__, (int)img_res_v.size, (t_img_enc_batch_us - t_img_enc_start_us) / 1000.0);
+        // printf("%s: %d segments encoded in %8.2f ms\n", __func__, (int)img_res_v.size, (t_img_enc_batch_us - t_img_enc_start_us) / 1000.0);
 
         const int32_t * image_grid = clip_image_grid(ctx_clip);
 
@@ -290,12 +290,12 @@ static bool encode_image_with_clip(clip_ctx * ctx_clip, int n_threads, const cli
         // clip_image_save_to_bmp(*tmp, "image_feature.bmp");
     }
 
-    printf("%s: image embedding created: %d tokens\n", __func__, *n_img_pos);
+    // printf("%s: image embedding created: %d tokens\n", __func__, *n_img_pos);
 
     const int64_t t_img_enc_end_us = ggml_time_us();
     float t_img_enc_ms = (t_img_enc_end_us - t_img_enc_start_us) / 1000.0;
 
-    printf("\n%s: image encoded in %8.2f ms by CLIP (%8.2f ms per image patch)\n", __func__, t_img_enc_ms, t_img_enc_ms / *n_img_pos);
+    // printf("\n%s: image encoded in %8.2f ms by CLIP (%8.2f ms per image patch)\n", __func__, t_img_enc_ms, t_img_enc_ms / *n_img_pos);
 
     return true;
 }
diff --git a/examples/llava/llava.h b/examples/llava/llava.h
index 2d40f3f1..8897b3d8 100644
--- a/examples/llava/llava.h
+++ b/examples/llava/llava.h
@@ -18,6 +18,7 @@
 #endif
 
 struct clip_ctx;
+struct clip_image_u8;
 
 #ifdef __cplusplus
 extern "C" {
diff --git a/llama.cpp b/llama.cpp
index 30d5eb32..9c940162 100644
--- a/llama.cpp
+++ b/llama.cpp
@@ -13266,7 +13266,9 @@ static void llama_log_internal(ggml_log_level level, const char * format, ...) {
 
 static void llama_log_callback_default(ggml_log_level level, const char * text, void * user_data) {
     (void) level;
-    (void) user_data;
-    fputs(text, stderr);
-    fflush(stderr);
+    bool * enable_log = static_cast<bool *>(user_data);
+    if (enable_log && *enable_log) {
+        fputs(text, stderr);
+        fflush(stderr);
+    }
 }
